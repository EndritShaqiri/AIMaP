{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ca2760d-11fa-4585-8261-fb42c4a773cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projectnb/cs640/students/endrit01/.conda/envs/aimal-310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/projectnb/cs640/students/endrit01/mt\")   # modify this path\n",
    "\n",
    "from AI_thrember.model import read_vectorized_features\n",
    "import lightgbm as lgb\n",
    "\n",
    "data_dir = \"/projectnb/cs640/students/endrit01/mt/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7c622b7-01d5-49dd-abd2-e53cf9810632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def read_vectorized_features(data_dir: Path | str, subset: str = \"train\"):\n",
      "    \"\"\"\n",
      "    Read vectorized features using numpy.memmap WITHOUT loading into RAM.\n",
      "    \"\"\"\n",
      "    data_path = Path(data_dir)\n",
      "    X_path = data_path / f\"X_{subset}.dat\"\n",
      "    y_path = data_path / f\"y_{subset}.dat\"\n",
      "\n",
      "    if not X_path.is_file():\n",
      "        raise ValueError(f\"Invalid subset file: {X_path}\")\n",
      "    if not y_path.is_file():\n",
      "        raise ValueError(f\"Invalid subset file: {y_path}\")\n",
      "\n",
      "    extractor = PEFeatureExtractor()\n",
      "    ndim = extractor.dim\n",
      "\n",
      "    # Determine number of rows in X via file size\n",
      "    bytes_per_row = ndim * 4   # float32 = 4 bytes\n",
      "    total_bytes = os.path.getsize(X_path)\n",
      "    nrows = total_bytes // bytes_per_row\n",
      "\n",
      "    # Memory-map WITHOUT loading into RAM\n",
      "    X = np.memmap(X_path, dtype=np.float32, mode=\"r\", shape=(nrows, ndim))\n",
      "    \n",
      "    # y is int32 so 4 bytes each\n",
      "    y_nbytes = os.path.getsize(y_path)\n",
      "    y_rows = y_nbytes // 4\n",
      "\n",
      "    # Multilabel case: shape is (nrows, n_labels)\n",
      "    if y_rows == nrows:\n",
      "        y = np.memmap(y_path, dtype=np.int32, mode=\"r\", shape=nrows)\n",
      "    else:\n",
      "        n_labels = y_rows // nrows\n",
      "        y = np.memmap(y_path, dtype=np.int32, mode=\"w+\", shape=(nrows, len(label_map)))\n",
      "\n",
      "    return X, y\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from AI_thrember.model import read_vectorized_features\n",
    "import inspect\n",
    "print(inspect.getsource(read_vectorized_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc87f6ad-7449-42eb-a7db-08db0f7d682b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scc-fi3\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 6] No such device or address",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhostname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Show the username and current node\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39muname()\u001b[38;5;241m.\u001b[39mnodename)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 6] No such device or address"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Show hostname of the machine running this notebook\n",
    "!hostname\n",
    "\n",
    "# Show the username and current node\n",
    "print(\"User:\", os.getlogin())\n",
    "print(\"Node:\", os.uname().nodename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efc704ea-a601-4ca7-bbc2-cb6413f8c9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected CPU cores: 32\n",
      "Thread environment configured.\n",
      "Dataset path: /projectnb/cs640/students/endrit01/mt/data\n",
      "\n",
      "===== STARTING FAMILY VECTORIZATION =====\n",
      "Preparing to vectorize raw features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5252000/5252000 [09:09<00:00, 9555.82it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5252000/5252000 [27:49<00:00, 3146.11it/s]\n",
      "100%|██████████| 1212000/1212000 [02:10<00:00, 9319.75it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1212000/1212000 [06:27<00:00, 3128.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing challenge set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6315/6315 [00:02<00:00, 2384.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== DONE =====\n",
      "Total time: 46.50 minutes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import multiprocessing\n",
    "import time\n",
    "from AI_thrember.model import create_vectorized_features\n",
    "\n",
    "# ================================================\n",
    "# 1. Detect and use ALL CPU cores allocated by SCC\n",
    "# ================================================\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "print(f\"Detected CPU cores: {num_cores}\")\n",
    "\n",
    "# Force Python + LightGBM + BLAS to use all cores\n",
    "os.environ[\"OMP_NUM_THREADS\"] = str(num_cores)\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = str(num_cores)\n",
    "os.environ[\"MKL_NUM_THREADS\"] = str(num_cores)\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = str(num_cores)\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = str(num_cores)\n",
    "\n",
    "print(\"Thread environment configured.\")\n",
    "\n",
    "# ================================================\n",
    "# 2. Set your dataset directory on SCC\n",
    "# ================================================\n",
    "data_dir = \"/projectnb/cs640/students/endrit01/mt/data\"\n",
    "print(\"Dataset path:\", data_dir)\n",
    "\n",
    "# ================================================\n",
    "# 3. Run FAMILY vectorization\n",
    "# ================================================\n",
    "print(\"\\n===== STARTING FAMILY VECTORIZATION =====\")\n",
    "start = time.time()\n",
    "\n",
    "create_vectorized_features(\n",
    "    data_dir=data_dir,\n",
    "    label_type=\"family\",   # MULTICLASS\n",
    "    class_min=1200           # keep only families with >=40 samples\n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "print(\"\\n===== DONE =====\")\n",
    "print(f\"Total time: {(end - start)/60:.2f} minutes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0992e2fa-6d28-4a29-816d-909d90b2d870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5252000, 2568)\n",
      "(5252000,)\n"
     ]
    }
   ],
   "source": [
    "from AI_thrember.model import read_vectorized_features\n",
    "\n",
    "X, y = read_vectorized_features(\"/projectnb/cs640/students/endrit01/mt/data\", \"train\")\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176ed375-1be2-4f3f-b131-0d0c38646a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (5252000, 2568)\n",
      "y: (5252000,)\n",
      "Unique classes: 223\n"
     ]
    }
   ],
   "source": [
    "X, y = read_vectorized_features(\"/projectnb/cs640/students/endrit01/mt/data\", \"train\")\n",
    "\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "print(\"Unique classes:\", len({label for labels in y for label in (labels if isinstance(labels, list) else [labels])}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d09629e-7406-4a26-8b13-28c54227df69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rungbu\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = \"/projectnb/cs640/students/endrit01/mt/data/2024-11-24_2024-11-30_Win32_test.jsonl\"\n",
    "\n",
    "with open(path) as f:\n",
    "    first = json.loads(next(f))\n",
    "\n",
    "print(first[\"family\"])\n",
    "print(type(first[\"family\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10d762df-0994-4b64-a4d5-4d59e2cf987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4e-45 2.8e-45 4.2e-45 5.6e-45 7.0e-45 8.4e-45 9.8e-45 1.1e-44 1.3e-44\n",
      " 1.4e-44 1.5e-44 1.7e-44 1.8e-44 2.0e-44 2.1e-44 2.2e-44 2.4e-44 2.5e-44\n",
      " 2.7e-44 2.8e-44 2.9e-44 3.1e-44 3.2e-44 3.4e-44 3.5e-44 3.6e-44 3.8e-44\n",
      " 3.9e-44 4.1e-44 4.2e-44 4.3e-44 4.5e-44 4.6e-44 4.8e-44 4.9e-44 5.0e-44\n",
      " 5.2e-44 5.3e-44 5.5e-44 5.6e-44 5.7e-44 5.9e-44 6.0e-44 6.2e-44 6.3e-44\n",
      " 6.4e-44 6.6e-44 6.7e-44 6.9e-44 7.0e-44]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y = np.memmap(\"/projectnb/cs640/students/endrit01/mt/data/ttest/y_train.dat\", dtype=np.float32, mode=\"r\")\n",
    "print(np.unique(y)[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff365804-f026-4d97-a377-6d78ff01e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique families in first 200: {'upatre', None, 'injurer', 'rugmi', 'innobundle', 'sality', 'berbew', 'titirez', 'diztakun', 'shodi', 'cayunamer', 'njrat', 'dumpex', 'cosmu', 'rungbu', 'scarletflash', 'chewbacca', 'cryptowall', 'allaple', 'lolbot', 'chinky', 'avrora', 'tinyloader', 'tepfer', 'neshta', 'wacatac', 'offloader', 'snackarcin', 'swisyn', 'ming', 'amadey', 'yomal', 'ipamor', 'shandagames', 'mofksys', 'puce', 'mydoom', 'convagent', 'vidar', 'aenjaris', 'softcnapp', 'barys', 'shutdown', 'axespec', 'lummastealer', 'vbclone', 'blihan', 'triusor', 'stealc', 'zeus', 'loudoffer', 'anyplacecontrol', 'bancteian', 'remcos'}\n",
      "Counts: {'upatre': 1, None: 122, 'injurer': 1, 'rugmi': 1, 'innobundle': 1, 'sality': 1, 'berbew': 20, 'titirez': 1, 'diztakun': 1, 'shodi': 1, 'cayunamer': 1, 'njrat': 1, 'dumpex': 1, 'cosmu': 3, 'rungbu': 1, 'scarletflash': 1, 'chewbacca': 1, 'cryptowall': 1, 'allaple': 1, 'lolbot': 1, 'chinky': 2, 'avrora': 1, 'tinyloader': 1, 'tepfer': 1, 'neshta': 2, 'wacatac': 1, 'offloader': 1, 'snackarcin': 1, 'swisyn': 1, 'ming': 1, 'amadey': 1, 'yomal': 1, 'ipamor': 1, 'shandagames': 1, 'mofksys': 1, 'puce': 1, 'mydoom': 1, 'convagent': 1, 'vidar': 1, 'aenjaris': 2, 'softcnapp': 1, 'barys': 1, 'shutdown': 1, 'axespec': 1, 'lummastealer': 2, 'vbclone': 1, 'blihan': 1, 'triusor': 1, 'stealc': 1, 'zeus': 1, 'loudoffer': 1, 'anyplacecontrol': 1, 'bancteian': 1, 'remcos': 1}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "path = \"/projectnb/cs640/students/endrit01/mt/data/2024-11-24_2024-11-30_Win32_test.jsonl\"\n",
    "\n",
    "families = []\n",
    "count = 0\n",
    "\n",
    "with open(path) as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        fam = obj.get(\"family\", None)\n",
    "        families.append(fam)\n",
    "        count += 1\n",
    "        if count >= 200:   # inspect first 200 samples\n",
    "            break\n",
    "\n",
    "print(\"Unique families in first 200:\", set(families))\n",
    "print(\"Counts:\", {k: families.count(k) for k in set(families)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4955cc8d-8355-4543-9a99-4f51fb8a137f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIMaL Python 3.10",
   "language": "python",
   "name": "aimal-310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
